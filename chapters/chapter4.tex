% Errors

\chapter{Implementation}
\label{cha:implementation}

In this chapter, we provide an overview of the design and implementation choices that guided the development of the register assignment pipeline and the underlying language JAIR. The implementation is structured in a modular way, beginning with the definition of the syntax and semantics of the language. We then detail the steps of register assignment, namely liveness analysis, graph coloring, and SSA destruction.

\section{JAIR}
\label{sec:jair}

The primary goal in defining the syntax of JAIR is to leverage Coqâ€™s type system to rule out as many ill-formed SSA programs as possible, as discussed in \Cref{sec:ssa}. We begin by describing how registers are represented in our language.

\subsection{Registers}

Our implementation uses two kinds of registers: virtual registers in the earlier phases of register assignment, and physical registers in the final phase. To support both use cases, we define \texttt{IR} module, which defines the syntax of our intermediate representation generically over these two types of registers.

The module requires the following parameters:
\begin{itemize}
    \item The register type \texttt{reg}, the set of all the registers we can choose from;
    \item The boolean equality function for the register type, namely \texttt{reg\_eqb};
    \item A proof for the decidability of the logical equality for the register type, namely \texttt{reg\_eq\_dec};
\end{itemize}

For virtual registers, we use the set of natural numbers, which, although bounded by Coq's runtime limits, can be treated as unbounded for our purposes.

\begin{lstlisting}[style=Coq]
Definition vreg := nat.
\end{lstlisting}

For physical registers, instead, we define a finite set that corresponds to the 64-bit general-purpose registers of the x86-64 architecture.

\begin{lstlisting}[style=Coq]
Inductive preg : Type :=
  | RAX
  | RBX
  | RCX
  (* ... *)
  | UNASSIGNED
.
\end{lstlisting}

We also include the \texttt{UNASSIGNED} register, this register is used as a default value for the coloring, removing the need of returning an optional value everywhere. Later we will prove that the coloring function will never return this constructor.

Throughout the implementation, every register is understood to be either virtual or physical depending on the phase of the compilation pipeline.

\subsection{Labels}

Initially, we opted for a labelless representation of basic blocks.
Later in the project we saw the necessity of introducing them for this specific reason: the $\phi$-instructions require labels to identify the incoming control flow since predecessors of a basic blocks are not ordered. Without labels a $\phi$-instruction would not know which one of the predecessors each of its arguments is bound to.

An alternative solution would be (given the single definition policy of SSA) to go back in the control flow to find which of the arguments of the $\phi$-instruction is defined. This approach proved too complicated, so we adopted labels, at the cost of introducing possible inconsistencies in the representation that we will later discuss in \Cref{subsec:limitations}.

\begin{lstlisting}[style=Coq]
Inductive lbl : Type :=
  | Normal : nat -> lbl
  | Point1 : nat -> lbl
  | Point2 : nat -> lbl.
\end{lstlisting}

The label type is defined with three constructors. The reason is explained more in detail in \Cref{sec:destruct}, but for now let's just say that the SSA destruction pass introduces additional basic blocks (at most two for each preexisting basic block). With the constructors \texttt{Point1} and \texttt{Point2} we identify these additional basic blocks in order to avoid collisions, whereas with the \texttt{Normal} constructor we identify the blocks that already existed before the destruction pass.

\subsection{ALU Instructions}

In order to perform computations, our intermediate representation must provide arithmetical and logical instructions.
We start by defining the \texttt{val} type which represents an operand of these instructions. It can be either an immediate integer, a register, or a pointer to a memory location (represented by a natural number):

\begin{lstlisting}[style=Coq]
Inductive val : Type :=
  | Imm (x : Z)
  | Reg (r : reg)
  | Ptr (p : nat).
\end{lstlisting}

We then define the type of expressions \texttt{expr}. These include register copies, memory loads, and arithmetical and logical operations. Expression depth is restricted to avoid unnecessary complexity and to preserve the linearity of the data structure.

\begin{lstlisting}[style=Coq]
Inductive expr : Type :=
  | Val : val -> expr
  | Load : val -> expr
  | Add : reg -> val -> expr
  | Sub : reg -> val -> expr
  (* ... *)
.
\end{lstlisting}

As you can see from the previous snippet, binary expressions always use a register as the first operand, preventing expressions that involve only constants since, in that case, the result could be computed during a previous step of constant folding. Another thing to note is that, for the sake of register assignment, a differentiation between unary, binary and n-ary expressions is unnecessary, as we are only concerned with the identities of the operands of an expression (the registers) and not the operators.

Finally, the instruction type \texttt{inst} reflects the core operations in our language. Instructions either define a register by assigning to it the result of an expression, or store a value into memory:

\begin{lstlisting}[style=Coq]
Inductive inst : Type :=
  | Def (r : reg) (e : expr)
  | Store (v : val) (r : reg).
\end{lstlisting}

The \texttt{Store} instruction is treated specially because it does not produce a result that can be assigned to a register. Therefore, it cannot be expressed as a \texttt{Def}.

\subsection{$\phi$-instructions}

In \Cref{sec:ssa} we defined a section of $\phi$-instructions as a parallel move based on the predecessor in the control flow.
We need an implementation that preserves this definition, to do so we start by defining the type of an argument of a $\phi$-instruction, namely \texttt{phi\_arg}.

\begin{lstlisting}[style=Coq]
Definition phi_arg : Type := (reg * lbl).
\end{lstlisting}

Semantically the \texttt{reg} instance is the source of the copy if the control flow comes from the \texttt{lbl} instance.

Finally we define $\phi$-instruction type, this is simply an assignment of one of the possible \texttt{phi\_arg}s to a destination \texttt{reg}.

\begin{lstlisting}[style=Coq]
Inductive phi : Type :=
| Phi : reg -> list phi_arg -> phi.
\end{lstlisting}

% Here, each \texttt{phi\_arg} pairs a register with a label identifying the originating block. Initially, we experimented with a label-free control flow representation that used direct pointers to blocks. However, as we will explain later, this made the semantics unnecessarily difficult to define, leading us to prefer label-based control flow.

\subsection{Blocks and Jump Instructions}

ALU instructions and $\phi$-instructions are defined separately enforcing the fact that in basic blocks the $\phi$-instructions appear first, followed by ALU instructions and finally by a jump instruction.
We define the jump instruction type in mutual recursion with the block type.

\begin{lstlisting}[style=Coq]
CoInductive block : Type :=
  | Block (l : lbl) (ps : list phi) (is : list inst) (j : jinst)
with jinst : Type :=
  | CondJump : cond -> reg -> val -> block -> block -> jinst
  | Jump : block -> jinst
  | Ret : reg -> jinst.
\end{lstlisting}

Control flow is encoded directly using block references instead of labels, preventing accidental jumps to nonexistent blocks. This definition naturally forms a control-flow graph, where blocks are nodes and jump instructions define the edges.

Finally, a CFG as we described in \Cref{subsec:cfg} is a set of blocks where we identify a start block and a control flow relation, it is sufficient to provide the following definition:

\begin{lstlisting}[style=Coq]
Definition program : Type := block.
\end{lstlisting}

Where the starting point of the CFG is the first block we encounter during a visit and the blocks set of the CFG is the set of blocks reachable from the first block.

Now that we covered the main parts of the JAIR implementation, we demonstrate the capabilities of our representation in \Cref{fig:example-jair} with an example of the Fibonacci function along with the same example in a general SSA form representation.

\begin{figure}[ht]
\centering
\begin{minipage}{0.65\textwidth}
\begin{lstlisting}[style=Coq]
Definition example_block_3 : block :=
  Block (Normal 3) [] [] (ret r(6)).

CoFixpoint example_block_2 : block :=
  Block (Normal 2) [
    r(3) <- phi [(0, Normal 1); (4, Normal 2)];
    r(4) <- phi [(1, Normal 1); (6, Normal 2)];
    r(5) <- phi [(2, Normal 1); (7, Normal 2)]
  ] [
    r(6) <- r(4) + r(3);
    r(7) <- r(5) - i(1)
  ] (
    if r(7) = i(1)
    then example_block_3
    else example_block_2
  ).

Definition example_block_1 : block :=
  Block (Normal 1) [] [
    r(0) <- i(0);  (* Second temp *)
    r(1) <- i(1);  (* First temp *)
    r(2) <- i(12)  (* Iterator *)
  ] (
    Jump example_block_2
  ).
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.30\textwidth}
\centering
\begin{tikzpicture}[
    node distance=10mm,
    every node/.style={draw, align=left, inner sep=4pt},
    >={Stealth}
]
  \node (entry)   at (0, 0)   {$r_0 \leftarrow 0$ \\ $r_1 \leftarrow 1$ \\ $r_2 \leftarrow 12$};
  \node (loop)    at (0, -3)  {$r_3 \leftarrow \phi(r_0, r_4)$ \\ $r_4 \leftarrow \phi(r_1, r_6)$ \\ $r_5 \leftarrow \phi(r_2, r_7)$ \\ $r_6 \leftarrow r_4 + r_3$ \\ $r_7 \leftarrow r_5 - 1$};
  \node (end)     at (0, -5.5)  {ret $r_6$};
  \draw[->] (entry) -- (loop);
  \draw[->] ([xshift=10pt]loop.south) to[out=315, in=45, looseness=4] ([xshift=10pt]loop.north);
  \draw[->] (loop) -- (end);
\end{tikzpicture}
\end{minipage}
\caption{The code for the Fibonacci function in JAIR along with the same code in a general SSA form representation}
\label{fig:example-jair}
\end{figure}

\subsection{Limitations}
\label{subsec:limitations}

Despite our efforts to use Coq's type system to rule out incorrect programs, certain ill-formed programs cannot be excluded purely by the syntax, we now provide examples of such cases.

A fundamental problem is that the two core policies of an SSA form represetnation are not enforced, namely multiple assignments to the same register and the use of undefined registers are still possible:

\begin{lstlisting}[style=Coq]
Definition double_assignment : block :=
  Block (Normal 0) [] [
    r(1) <- i(0);
    r(1) <- i(1)
  ]
  (ret r(1)).

Definition undefined_variable : block :=
  Block (Normal 0) [] [r(1) <- r(0)] (ret r(1)).
\end{lstlisting}

Similarly, uniqueness of labels is not enforced, which can lead to conflicting block labels, as shown in the following example:

\begin{lstlisting}[style=Coq]
CoFixpoint double_lbl_1 : block := Block (Normal 0) [] [] (Jump double_lbl_2)
  with double_lbl_2 : block := Block (Normal 0) [] [] (Jump double_lbl_1).
\end{lstlisting}

Finally, $\phi$-instructions may include inconsistent or invalid arguments. For example, the number of the predecessors listed in a $\phi$-instruction may not match the actual number of predecessors:

\begin{lstlisting}[style=Coq]
Definition ill_formed_phi_2 : block :=
  Block (Normal 1) [r(1) <- phi [(0, 0);]] [] (ret r(0)).
Definition ill_formed_phi_1 : block :=
  Block (Normal 0) [] [] (Jump ill_formed_phi_2).
\end{lstlisting}

Although these issues cannot be resolved by the type system alone, they can be caught during a previous semantic analysis phase.

\section{A JAIR Interpreter}
\label{sec:jair-int}

We now implement a small-step interpreter for our intermediate representation, we do this for two reasons.
The first one is to clearly state the semantics of JAIR. The second one is that, in order to test register assignemnt, we will compare the result of a program executed on the interpreter virtual machine with the result of the same program executed on bare hardware, if the two results match this will suggest that the semantics of the program are preserved even after register assignment.
The definition of the virtual machine is straightforward as its components are just the register file, implemented as a map from registers to integers, and the memory, implemented as list of integers.

\begin{lstlisting}[style=Coq]
Inductive vm : Type :=
  | Vm : (reg -> Z) -> list Z -> vm.
\end{lstlisting}

The only remaining task is to define a function that simulates program execution, ideally we would want that function to have type \texttt{vm -> program -> vm} taking the initial state of the virtual machine and the program as inputs and returning the new state of the virtual machine.
Unfortunately, as we mentioned in \Cref{subsec:funterm}, Coq does not allow for the definition of functions of which we cannot prove termination, and proving it for this function would entail solving the halting problem. We thus resort to using fuel based recursion for this case.

\begin{lstlisting}[style=Coq]
Fixpoint run (m : vm) (p : program) (fuel : nat) : vm :=
  match p, fuel with
  | _, O => m
  | Block _ _ is j, S fuel' =>
    let m := run_insts m is in
    match j with
    | CondJump c r v b1 b2 =>
      if eval_cond m c r v then
        run (run_phis m p b1) b1 fuel'
      else
        run (run_phis m p b2) b2 fuel'
    | Jump b1 => run (run_phis m p b1) b1 fuel'
    | Ret r => set_reg m 0 (get_reg m r)
    end
  end.
\end{lstlisting}

The procedure works this way: if we are out of fuel we terminate and we return the current state of the virtual machine, otherwise we proceed with the computation.
We run the body of instructions of the current block with the function \texttt{run\_insts}, yielding a new state of the virtual machine. We then treat each jump instruction differently, in the case of a conditional jump we evaluate the condition with the \texttt{eval\_cond} function, in the other two cases no evaluation is needed. Finally, before jumping to the next block we execute its $\phi$-instructions, to do so we call the \texttt{run\_phis} function  passing as arguments the virtual machine, the current block and the successor block.
We continue with the computation until we either run out of fuel or we reach the \texttt{Ret} instruction, saving the result of the program to register zero.

\section{Liveness Analysis}
\label{sec:liveness}

In this phase, we compute the set of live variables at each program point. This step is crucial for determining which variables interfere and, therefore constitute an edge of the interference graph.

Generally a liveness analysis algorithm works this way:
we start from the last instruction of the program and go back to the start instruction in a post-order fashion, while we do that we compute the following sets for each instruction:
\begin{itemize}
  \item \texttt{live\_in[i]} which contains the variables that are live \textit{before} the execution of instruction \texttt i;
  \item \texttt{live\_out[i]} which instead contains the variables live \textit{after} the execution of \texttt i;
  \item \texttt{def[i]} are the variables created by the instruction, in our language this set is either a singleton or the empty set as we can only define at most one variable per instruction;
  \item \texttt{use[i]} are the variables used as arguments by the instruction, at most two in our language since that is the maximum arity of our expressions;
\end{itemize}

Since in our language instructions can be of three different kinds we define different dataflow equations for each instruction type.

We start by defining the dataflow equations for the ALU instructions:
\begin{align*}
  \texttt{live\_in[i]} &= \texttt{use[i]} \cup (\texttt{live\_out[i]} \setminus \texttt{def[i]}) \\
  \texttt{live\_out[i]} &= \bigcup \limits_{\texttt j \in \texttt{succ[i]}} \texttt{live\_in[j]}
\end{align*}

Since the computation is done backwards we start with the \texttt{live\_out[i]} set, which must contain the variables that are required by the successors of \texttt i. The
\texttt{live\_in[i]} set must instead contain the variables required by \texttt i, identified by \texttt{use[i]} and the variables that are required by the next instructions, identified by \texttt{live\_out[i]} $\setminus$ \texttt{def[i]}.
Here there are some things to note, first of all that the set $\texttt{live\_out[i\_n]} = \emptyset$ where \texttt{i\_n} is the last instruction of the program, since no variables are live after the program ends, we start from this assumption at the beginning of the procedure.

For jump instructions instead, the dataflow equations are similar, we just simplify the first dataflow equation by removeing \texttt{def[i]} as jump instructions never define variables.

Now, because of the different semantics of $\phi$-instructions we must define their dataflow equations separately. In particular we define the liveness information of the whole section instead of for single $\phi$-instructions, this is because, as was explained in \Cref{subsec:phi}, these kind of instructions are executed parallelly.
We compute:
\begin{align*}
  \texttt{live\_in[ps]} &= \texttt{phi\_defs[ps]} \cup \texttt{live\_out[ps]} \\
  \texttt{live\_out[ps]} &= \bigcup \limits_{\texttt j \in \texttt{succ[ps]}} \texttt{live\_in[j]}
\end{align*}
where \texttt{phi\_defs[ps]} contains the left-hand sides of the $\phi$-instructions.

Starting again with \texttt{live\_out[ps]}, we define it as the union of the variables that are live before the first ALU instruction of the block. \texttt{live\_in[ps]} is instead the set of variables that are defined in the $\phi$-instructions together with the variables that are required after the $\phi$-instructions, intuitively the variables in \texttt{phi\_defs[ps]} are already defined before reaching the start of the block since their execution happens during the jump.

\section{Register Assignment}
\label{sec:ra}

As explained in \Cref{subsec:ssara} register assignment is considered equivalent to the task of graph coloring of the interference graph, but, before starting with the coloring let's recall \Cref{def:ig}. A chordal graph is a graph for which there exists a perfect elimination ordering, that is, there exists a simplicial node such that, if we remove that node the graph is still chordal and, the perfect elimination ordering is then the ordering in which those nodes are removed.
To perform the coloring we then proceed this way:
\begin{itemize}
  \item We use the liveness information to build the interference graph;
  \item We iteratively remove the simplicial nodes from the interference graph obtaining a perfect elimination ordering;
  \item We reinsert the nodes of the PEO in \textit{reverse} order into the interference graph and, at the same time, we assign them a color that is not already taken by their (partially colored) neighborhoods;
\end{itemize}

We now proceed with the implementation of the passes that we just described.

\subsection{Interference Graph Construction}

Now that we extracted the liveness information from our CFG we use it to build the interference graph.
The reasoning behind the creation of the interference graph is straightforward, we go through every live set computed in the previous step and we insert a clique containing its elements. This follows intuitively by the fact that if two variables are live in the same instruction then they interfere as per \Cref{def:ig}.

The function used to populate the interference graph is the following:

\begin{lstlisting}[style=Coq]
Definition get_ig (pi : ProgramInfo.dict) : InterfGraph.dict :=
  fold_left
    (fun g l =>
      match ProgramInfo.get pi l with
      | Some (BlockInfo iis) => ig_insert_instinfos g iis
      | None => g
      end)
    (ProgramInfo.keys pi)
    InterfGraph.empty.
\end{lstlisting}

Where \texttt{ig\_insert\_instinfos} is a function that given an interference graph and a list of live sets returns a graph where a clique containing the elements of the set is added for each element of the list.

\subsection{Obtaining a PEO}

Recalling \Cref{def:simplicial} we implement a function that determines whether a node of a graph is simplicial:

\begin{lstlisting}[style=Coq]
Definition is_simplicialb (g : InterfGraph.dict) (r : reg) : bool :=
  let nbors := InterfGraph.get g r in
  regs_mem r (InterfGraph.keys g) &&
  is_cliqueb g nbors.
\end{lstlisting}

In this case \texttt{InterfGraph.get} is simply the function to get the neighborhood of a node, \texttt{regs\_mem} is a boolean function to test membership of a node to a set and finally \texttt{is\_cliqueb} is a boolean function to test whether a set is a clique in a specific graph.
For the purpose of this project, let's ignore the complexity of the various functions as we are only concerned in building a framework that makes it easy to perform formal verification. Anyway, be reassured that all the functions run in polynomial time.

We now define a function that lets us find a simplicial node in the graph:

\begin{lstlisting}[style=Coq]
Definition find_next (g : InterfGraph.dict) : option reg :=
  find (is_simplicialb g) (InterfGraph.keys g).
\end{lstlisting}

As explained in the second step of the coloring procedure, at each iteration we need to find a simplicial node, and that's exactly what \texttt{find\_next} does. Note that the output node is an optional value, since the function may also receive a non chordal graph which may not have a simplicial node. This in reality could not be the case since we make the assumption that the interference graphs we receive are chordal. Unfortunately because of that we need to propagate the option wrapper to all of the return values of the next functions.
In the extracted code, upon receiving a \texttt{None} constructor we will to throw an exception, signaling to the user that the interference graph (and likely even the initial JAIR program) is malformed.

Now we proceed with the step function for the \texttt{eliminate} function:

\begin{lstlisting}[style=Coq]
Definition eliminate_step
  (g : InterfGraph.dict) : option (reg * InterfGraph.dict):=
  match find_next g with
  | Some next =>
    Some (next, ig_remove_node g next)
  | None => None
  end.
\end{lstlisting}

It takes an interference graph which is chordal, finds a simplicial node, removes it, and returns both the removed node and the resulting graph.
Note that, if the precondition of the input graph being chordal is met, the function will never return the \texttt{None} constructor. furthermore, the resulting graph will also be chordal.
We will talk more about the postconditions in \Cref{cha:verification}.

Finally we can move into the \texttt{eliminate} function, that is, the function for obtaining the PEO:

\begin{lstlisting}[style=Coq]
Function eliminate
  (g : InterfGraph.dict) {measure InterfGraph.size g} : list reg :=
  match eliminate_step g with
  | Some (next, g') => next :: (eliminate g')
  | None => nil
  end.
\end{lstlisting}

The definition of the function is straightforward, we take an interference graph and we remove the simplicial nodes until it becomes the empty graph, constantly appending the removed node at the end of the list.
As was mentioned in \Cref{subsec:funterm} Coq has trouble automatically verifying the termination of this function, because of that we add an annotation that tells it that the fixed point lies in the size of the interference graph. We will write a proof for this in \Cref{cha:verification}.

\subsection{Coloring}
\label{subsec:coloring}

The intuition behind the coloring algorithm is the following, first of all we make the following assumptions:

\begin{itemize}
  \item The interference graph $G$ obtained from the previous phase is chordal, which we know from \Cref{thm:chordal-chromatic};
  \item The chromatic number $\omega(G)$ is less then or equal to the number of available registers $k$, that is, we assume that spilling already happened, making the graph $k$-colorable;
\end{itemize}

Now take into consideration a single iteration of the algorithm mentioned at the beginning of \Cref{sec:ra}. The node we are about to color is simplicial, meaning that its neighborhood forms a clique. Even if not every element of the neighborhood is colored, the colored neighbors still form a clique (a subset of a clique is still a clique) meaning that the next step consists in finding a color that is not used by the colored neighbors, which is always possible since we assume that $\omega(G) \leq k$.

Given this introduction about the intuition of the algorithm, we start with the definition of the \texttt{Coloring} object as a dictionary from virtual registers to physical registers, this object will be the output of the coloring phase.

As we mentioned before, at each position of the \textit{reversed} PEO we find a node whose colored neighborhood forms a clique, because of that, in order to assign this node a new color we pick a random one from the complement of the neighborhood colors. We define a function specifically for this purpose.

\begin{lstlisting}[style=Coq]
Definition preg_compl (colors : set preg) : option preg :=
  match IRPreg.regs_diff preg_allowed colors with
  | nil => None
  | c :: _ => Some c
  end.
\end{lstlisting}

Here, given a set of registers we calculate the difference with the set of registers \texttt{preg\_allowed} and we extract an arbitrary element from it, note that the result of this function is optional since, if we run out of registers, we are not able to extract from the complement and ultimately perform register assignment. This, however, is an unexpected case solved by spilling.

Now we use the function we just defined to color a single node given its interference graph and the current coloring:

\begin{lstlisting}[style=Coq]
Definition get_color
  (v : IRVreg.reg) (g : InterfGraph.dict) (c : Coloring.dict)
  : option IRPreg.reg :=
  let nbors := InterfGraph.get g v in
  let used := map (Coloring.get c) nbors in
  preg_compl used.
\end{lstlisting}

Finally we introduce the function to obtain the complete coloring of the interference graph, the procedure is the same as explained at the beginning of \Cref{subsec:coloring}.

\begin{lstlisting}[style=Coq]
Definition get_coloring (peo : list IRVreg.reg) (g : InterfGraph.dict)
  : option Coloring.dict :=
  let fix get_coloring_aux (peo : list IRVreg.reg) (c : Coloring.dict)
    : option Coloring.dict :=
    match peo with
    | nil => Some c
    | v :: peo =>
      match get_color v g c with
      | Some p =>
        let c := Coloring.update c v p in
        get_coloring_aux peo c
      | None => None
      end
    end
  in
  get_coloring_aux (rev peo) Coloring.empty.
\end{lstlisting}

\section{SSA Destruction}
\label{sec:destruct}

The final phase before emitting assembly is SSA destruction, which consists in the translation of $\phi$-instructions into moves. This final phase is required since $\phi$-instructions are not implemented in common architectures.
We mentioned in \Cref{subsec:phi} that a section of $\phi$-instructions behaves as a parallel copy, our goal is to find a sequence of instruction that preserves this property. The translation is straightforward for some cases, take the following example, where $x \to y$ represents moving the content of register $x$ to register $y$:
\[
  r_1 \to r_2, r_2 \to r_3, r_3 \to r_4
\]
Solving this problem basically consists in reordering the moves so that no value is overwritten, the solution for this case is:
\[
  r_3 \to r_4, r_2 \to r_3, r_1 \to r_2
\]
Unfortunately some other cases are non-trivial, namely those who contain loops such as:
\[
  r_1 \to r_2, r_2 \to r_3, r_3 \to r_1
\]
There are two ways of solving these cases, we could try to find a sequence of swap operations such that at the end of the computation each value ends up in the intended register, this first option could be implemented using a swap instruction (like \texttt{xchg}) if supported by the architecture, or by using the XOR operator. Another option would be to reserve a special register \texttt{tmp} to perform the swaps. In our implementation we use an already verified algorithm [cit] that uses temporary variables. Given the previous example we would end up with the following result:
\[
  r_1 \to \texttt{tmp}, r_3 \to r_1, r_2 \to r_3, \texttt{tmp} \to r_2
\]
Now that we are able to compile a parallel move we visit the control flow graph while translating one section of $\phi$-instructions at a time.
We identify three different cases when performing the destruction, one for each jump instruction:
\begin{itemize}
  \item When visiting a basic block that ends with a \texttt{CondJump} we need to translate two different parallel moves, one for each of the two successors, since we cannot append two different parallel move translations into the current block, as they would conflict with each other, we need to create two new basic blocks, each of which contains the corresponing translation of the parallel move and then an unconditional jump to the successor. We also give them the same label as the current block but using constructors \texttt{Point1} and \texttt{Point2} to avoid a collisions with the current block, which instead uses the \texttt{Normal} constructor;
  \item If instead we encounter a jump instruction, the translation simply consists in appending the translated parallel move at the end of the instructions of the current block;
  \item Finally the return instruction does not require any translation, as it is the last instruction of a program;
\end{itemize}

In \Cref{fig:destruct} we can see an example of SSA destruction in action, in the visit first we encounter an unconditional jump, then a conditional jump and finally a return instruction.


\begin{figure}[h]
\centering
\begin{minipage}{0.45\textwidth}
\centering
  \begin{tikzpicture}[
      node distance=10mm,
      every node/.style={draw, align=left, inner sep=4pt},
      >={Stealth}
    ]
    \node (entry)   at (0, 0)   {$r_0 \leftarrow 0$};
    \node (loop)    at (0, -2)  {$r_1 \leftarrow \phi(r_0, r_2)$ \\ $r_2 \leftarrow r_1 + 1$};
    \node (end)     at (0, -4)  {ret $r_2$};
    \draw[->] (entry) -- (loop);
    \draw[->] ([xshift=10pt]loop.south) to[out=315, in=45, looseness=8] ([xshift=10pt]loop.north);
    \draw[->] (loop) -- (end);
    \end{tikzpicture}
\end{minipage}
\hfill
\begin{minipage}{0.45\textwidth}
\centering
  \begin{tikzpicture}[
      node distance=10mm,
      every node/.style={draw, align=left, inner sep=4pt},
      >={Stealth}
    ]
    \node (entry)   at (0, 0)     {$r_0 \leftarrow 0$ \\ $r_1 \leftarrow r_0$};
    \node (loop)    at (0, -2)    {$r_2 \leftarrow r_1 + 1$};
    \node (loop1)   at (-1.5, -4) {nop};
    \node (loop2)   at (1.5, -4)  {$r_1 \leftarrow r_2$};
    \node (end)     at (0, -6)    {ret $r_6$};
    \draw[->] (entry) -- (loop);
    \draw[->] (loop) -- (loop1);
    \draw[->] (loop) -- (loop2);
    \draw[->] (loop2.south) to[out=315, in=45, looseness=3] ([xshift=10pt]loop.north);
    \draw[->] (loop1) -- (end);
    \end{tikzpicture}
\end{minipage}
\caption{SSA destruction of a loop}
\label{fig:destruct}
\end{figure}

\todo{Add description of registers implementation either in \Cref{sec:jair} or \Cref{cha:verification}}

\section{Extraction}
\label{sec:extract}

After defining all of the passes of our register assignment pipeline, we extract them into OCaml.
In particular we extract the following functions:
\begin{itemize}
  \item \texttt{Vm.run} to interpret our programs;
  \item \texttt{LivenessInfo.analyze\_program} to perform liveness analysis;
  \item \texttt{InterfGraph.get\_ig} to obtain the interference graph;
  \item \texttt{Peo.eliminate} to obtain the PEO;
  \item \texttt{Color.get\_coloring} to construct our coloring map;
  \item \texttt{Color.color\_program} to convert our program from the virtual registers implementation to one using physical registers implementation;
  \item \texttt{Destruct.ssa\_destruct} to remove the $\phi$-instructions;
\end{itemize}

After extracting we create a function to compose our pipeline:

\begin{lstlisting}[style=OCaml]
let regalloc irvreg_program =
  let (programinfo, _) = analyze_program irvreg_program fuel_analyze in
  let interfgraph = get_ig programinfo in
  let peo = eliminate interfgraph in
  let coloring =
    match get_coloring peo interfgraph with
    | Some c -> c
    | None -> failwith "Not enough registers to complete allocation"
  in
  let irpreg_program = color_program coloring irvreg_program in
  ssa_destruct fuel_destruct  irpreg_program
;;
\end{lstlisting}