% Errors

\chapter{Implementation}
\label{cha:implementation}

In this chapter, we provide an overview of the design and implementation choices that guided the development of the register allocator and the underlying language JAIR. The implementation is structured in a modular way, beginning with the definition of the syntax and semantics of the language. We then detail the steps required to perform register allocation, namely liveness analysis, graph coloring, and SSA destruction.

\section{JAIR}
\label{sec:jair}

The primary goal in defining the syntax of JAIR is to leverage Coqâ€™s type system to rule out as many ill-formed SSA programs as possible, as discussed in \Cref{sec:ssa}. We begin by describing how registers are represented in our language.

\subsection{Registers}

Our implementation uses two kinds of registers: virtual registers in the earlier phases of register allocation, and physical registers in the final phase. To support both use cases, we define the syntax of our intermediate language generically over the types of registers.

In order to do so we need to provide the following parameters to the generic implementation:
\begin{itemize}
    \item The register type \texttt{reg} which is the set of all the possible registers we can choose from;
    \item The boolean equality function for the register type, namely \texttt{reg\_eqb};
    \item A proof for the decidability of the logical equality for the register type, namely \texttt{reg\_eq\_dec};
\end{itemize}

Coq modules provide a convenient mechanism to abstract over register types that also works well with extraction.

Each instantiation of this module corresponds to a concrete intermediate representation. For virtual registers, we use the set of natural numbers, which, although bounded by Coq's runtime limits, can be treated as unbounded for our purposes.

\begin{alltt}
Definition vreg := nat.
\end{alltt}

For physical registers, we define a finite set that corresponds to the 64-bit general-purpose registers of the x86 architecture.

\begin{alltt}
Inductive preg : Type :=
  | RAX
  | RBX
  | RCX
  (* ... *)
.
\end{alltt}

Throughout the implementation, every register is understood to be either virtual or physical depending on the phase of the compilation pipeline.

\subsection{Labels}

Initially we opted for a labelless representation of basic blocks.
But then, later in the project we saw the necessity of introducing them for this specific reason: the $\phi$ instructions require labels to identify the incoming control flow, since predecessors of a basic blocks are not ordered. Without labels a $\phi$ instruction would not know which one of the predecessors each variable is bound to.

An alternative solution would be (since SSA programs only define variables only one) to go back in the control flow to find which of the arguments of the $\phi$ instruction is defined. This second approach turned out to be too complicated, so we decided to stick with the label implementation, at cost of introducing some possible inconsistencies of which we will talk later in \Cref{subsec:limitations}.

\begin{alltt}
Inductive lbl : Type :=
  | Normal : nat -> lbl
  | Point1 : nat -> lbl
  | Point2 : nat -> lbl.
\end{alltt}

The label type is defined with three constructors. The reason is explained more in detail in \Cref{sec:destruct}, but for now let's just say that the SSA destruction pass introduces additional basic blocks (at most two for each preexisting basic block), with constructors \texttt{Point1} and \texttt{Point2}, that we need to differentiate from the original basic blocks, with the constructor \texttt{Normal}.

\subsection{ALU Instructions}

In order to perform computation our intermediate representation must be equipped with arithmetic and logic instructions.
We start by defining the value type \texttt{val} which can be either an immediate integer, a register, or a pointer to a memory location (represented by a natural number):

\begin{alltt}
Inductive val : Type :=
  | Imm (x : Z)
  | Reg (r : reg)
  | Ptr (p : nat).
\end{alltt}

We then define the type of expressions \texttt{expr}. These include register copies, memory loads, and arithmetic and logic operations. Expression depth is restricted to avoid unnecessary complexity and to preserve the linearity of the data structure thus reducing the complexity of the foreseen algorithms:

\begin{alltt}
Inductive expr : Type :=
  | Val : val -> expr
  | Load : val -> expr
  | Add : reg -> val -> expr
  | Sub : reg -> val -> expr
  (* ... *)
.
\end{alltt}

Binary expressions always use a register as the first operand, preventing expressions that involve only constants, since in that case the result could be computed trivially during a previous step of the compilation. Another thing to note is that, for the sake of register allocation, a differentiation between unary, binary and n-ary expressions is useless as we are only concerned with the operands of an expression (the registers) and not the operator.

Finally, the type of the instructions \texttt{inst} reflects the core operations in our language. Instructions either define a register by assigning it the result of an expression, or store a value into memory:

\begin{alltt}
Inductive inst : Type :=
  | Def (r : reg) (e : expr)
  | Store (v : val) (r : reg).
\end{alltt}

The \texttt{Store} instruction is treated specially because it does not produce a result that can be assigned to a register. For this reason, it cannot be expressed as a \texttt{Def}.

\subsection{$\phi$ Instructions}

In \Cref{sec:ssa} we defined $\phi$ nodes as parallel moves based on the control flow predecessor.
We need a definition that preserves this information, to do so we start by defining the type of an argument of a $\phi$ instruction, namely \texttt{phi\_arg}. Semantically the \texttt{reg} instance is the source of the copy if the control flow comes from the \texttt{lbl} instance.

\begin{alltt}
Definition phi_arg : Type := (reg * lbl).
\end{alltt}

Finally we define the type of a $\phi$ instruction, this is simply an assignment of one of the possible \texttt{phi\_arg}s to a destination register \texttt{r}.

\begin{alltt}
Inductive phi : Type :=
| Phi (r : reg) (rs: list phi_arg).
\end{alltt}

% Here, each \texttt{phi\_arg} pairs a register with a label identifying the originating block. Initially, we experimented with a label-free control flow representation that used direct pointers to blocks. However, as we will explain later, this made the semantics unnecessarily difficult to define, leading us to prefer label-based control flow.

\subsection{Blocks and Jump Instructions}

ALU instructions and $\phi$ instructions are defined separately so that we can enforce that in basic blocks the $\phi$ section appears first, followed by ALU instructions and finally by a jump instruction.
We define the type of the jump instruction, in mutual recursion with the block type.

\begin{alltt}
CoInductive block : Type :=
  | Block (l : lbl) (ps : list phi) (is : list inst) (j : jinst)
with jinst : Type :=
  | CondJump : cond -> reg -> val -> block -> block -> jinst
  | Jump : block -> jinst
  | Ret : reg -> jinst.
\end{alltt}

Control flow is encoded directly using block references instead of labels, preventing accidental jumps to nonexistent blocks. This definition naturally forms a control-flow graph, where blocks are nodes and jump instructions define the edges.

Finally since a CFG as we described in \Cref{subsec:cfg} is a set of blocks where we identify a start block and a control flow relation, it is sufficient to provide the following definition, where the starting point of the CFG is the first block we encounter during a visit and the blocks set of the CFG is the set of blocks reachable from the first block.

\begin{alltt}
Definition program : Type := block.
\end{alltt}

The following is an example of a function that calculates the fibonacci of twelve written in JAIR, we show the corresponding program displayed in a general SSA form representation in \Cref{fig:example-jair}.

\begin{alltt}
Definition example_block_3 : block :=
  Block (Normal 3) [] [] (ret r(6)).

CoFixpoint example_block_2 : block :=
  Block (Normal 2) [
    r(3) <- phi [(0, Normal 1); (4, Normal 2)];
    r(4) <- phi [(1, Normal 1); (6, Normal 2)];
    r(5) <- phi [(2, Normal 1); (7, Normal 2)]
  ] [
    r(6) <- r(4) + r(3);
    r(7) <- r(5) - i(1)
  ] (
    if r(7) = i(1) then example_block_3 else example_block_2
  ).

Definition example_block_1 : block :=
  Block (Normal 1) [] [
    r(0) <- i(0);  (* Second block *)
    r(1) <- i(1);  (* First block *)
    r(2) <- i(12)  (* Iterator*)
  ] (
    Jump example_block_2
  ).
\end{alltt}

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[
        node distance=10mm,
        every node/.style={draw, align=left, inner sep=4pt},
        >={Stealth}
    ]
    \node (entry)   at (0, 0)   {$r_0 \leftarrow 0$ \\ $r_1 \leftarrow 1$ \\ $r_2 \leftarrow 12$};
    \node (loop)    at (0, -3)  {$r_3 \leftarrow \phi(r_0, r_4)$ \\ $r_4 \leftarrow \phi(r_1, r_6)$ \\ $r_5 \leftarrow \phi(r_2, r_7)$ \\ $r_6 \leftarrow r_4 + r_3$ \\ $r_7 \leftarrow r_5 - 1$};
    \node (end)     at (0, -5.5)  {ret $r_6$};

    \draw[->] (entry) -- (loop);
    \draw[->] ([xshift=10pt]loop.south) to[out=315, in=45, looseness=4] ([xshift=10pt]loop.north);
    \draw[->] (loop) -- (end);
    \end{tikzpicture}
    \caption{Fibonacci of 12 in a general SSA form representation}
    \label{fig:example-jair}
\end{figure}

\subsection{Limitations}
\label{subsec:limitations}

Despite our efforts to use Coq's type system to rule out incorrect programs, certain ill-formed programs cannot be excluded purely by the syntax. We provide examples of such cases using custom notations for readability.

For instance, multiple assignments to the same register or the use of undefined registers are still possible:

\begin{alltt}
Definition double_assignment : block :=
  Block 0 [] [
    r(1) <- i(0);
    r(1) <- i(1)
  ]
  (ret r(1)).

Definition undefined_variable : block :=
  Block 0 [] [r(1) <- r(0)] (ret r(1)).
\end{alltt}

Similarly, labels are not globally unique, which can lead to conflicting block labels:

\begin{alltt}
CoFixpoint double_lbl_1 : block := Block 0 [] [] (Jump double_lbl_2)
  with double_lbl_2 : block := Block 0 [] [] (Jump double_lbl_1).
\end{alltt}

Finally, $\phi$ instructions may include inconsistent or invalid arguments. For example, the number or identity of predecessors listed in a $\phi$ instruction may not match the actual control-flow structure:

\begin{alltt}
Definition ill_formed_phi_2 : block :=
  Block 1 [r(0) <- phi [(1, 0); (2, 1); (3, 2)]] [] (ret r(0)).
Definition ill_formed_phi_1 : block :=
  Block 0 [] [] (Jump ill_formed_phi_2).
\end{alltt}

Although these issues cannot be resolved by the type system alone, they are caught during further semantic analysis or preprocessing phases.

\section{A JAIR Interpreter}
\label{sec:jair-int}

We now implement a small-step interpreter for our intermediate representation, here we have two goals.
The first one is to clearly state the semantics of JAIR. The second one is that, in order to test our register allocator, we will compare the result of a program executed on the interpreter virtual machine with the result of the same program executed on bare hardware, if the two results match this will suggest that the semantics of the program are preserved even after the register allocation.
The definition of the virtual machine is straighforward as its components are just the register file, implemented as a map from registers to integers and the memory, implemented as list of integers.

\begin{alltt}
Inductive vm : Type :=
  | Vm : (reg -> Z) -> list Z -> vm.
\end{alltt}

Now the only thing left is to define a function that simulates the execution of a program, ideally we would want that function to have type \texttt{vm -> program -> vm} taking the initial state of the virtual machine and the program as inputs and returning the new state of the virtual machine.
Unfortunately, as we mentioned in \Cref{subsec:funterm}, Coq does not allow for the definition of functions of which we cannot prove termination, and proving it for this function would entail solving the halting problem. We thus resort to using fuel based recursion for this case.

\begin{alltt}
Fixpoint run (m : vm) (p : program) (fuel : nat) : vm :=
  match p, fuel with
  | _, O => m
  | Block _ _ is j, S fuel' =>
    let m := run_insts m is in
    match j with
    | CondJump c r v b1 b2 =>
      if eval_cond m c r v then
        run (run_phis m p b1) b1 fuel'
      else
        run (run_phis m p b2) b2 fuel'
    | Jump b1 => run (run_phis m p b1) b1 fuel'
    | Ret r => set_reg m 0 (get_reg m r)
    end
  end.
\end{alltt}

The procedure works this way: if we are out of fuel we terminate and we return the current state of the virtual machine, otherwise we proceed with the computation.
We run the body of instructions of the current block with the function \texttt{run\_insts}, thus creating a new state of the virtual machine. We then treat each jump instruction differently, in the case of a conditional jump we evaluate the condition with the \texttt{eval\_cond} function, in the other two cases no evaluation is needed. Finally, before jumping to the next block we execute its $\phi$ instructions, to do so we call the \texttt{run\_$\phi$s} function  passing as arguments the virtual machine, the current block and the successor block.
We continue with the computation until we either run out of fuel or we reach the \texttt{Ret} instruction, saving the result of the program to register zero.

\section{Liveness Analysis}
\label{sec:liveness}

In this phase, we compute the set of live variables at each program point. This step is crucial for determining which variables interfere and, therefore constitute an edge of the interference graph.

Generally a liveness analysis algorithm works this way:
we start from the last instruction of the program and go back to the start instruction in a post-order fashion, while we do that we compute the following sets:
\begin{itemize}
  \item \texttt{live\_in[i]} which contains the variables that are live \textit{before} the execution of instruction \texttt i;
  \item \texttt{live\_out[i]} which instead contains the variables live \textit{after} the execution of \texttt i;
  \item \texttt{def[i]} are the variables created by the instruction, in our language this set is either a singleton or the empty set as we can only define at most one variable per instruction;
  \item \texttt{use[i]} are the variables used as arguments by the instruction, at most two in our language since this is the maximum arity for the expressions;
\end{itemize}

Since in our language instructions can be of three different kinds we define different dataflow equations for each instruction type.

We start by defining the dataflow equations for the ALU instructions:
\begin{align*}
  \texttt{live\_in[i]} &= \texttt{use[i]} \cup (\texttt{live\_out[i]} \setminus \texttt{def[i]}) \\
  \texttt{live\_out[i]} &= \bigcup \limits_{\texttt j \in \texttt{succ[i]}} \texttt{live\_in[j]}
\end{align*}

Since the computation is done backwards we start with the \texttt{live\_out[i]} set, which must contain the variables that are required by the successors of \texttt i. The
\texttt{live\_in[i]} set must instead contain the variables required by \texttt i, identified by \texttt{use[i]} and the variables that are required by the next instructions, identified by \texttt{live\_out[i]} $\setminus$ \texttt{def[i]}.
Here there are some things to note, first of all that the set $\texttt{live\_out[i\_n]} = \emptyset$ where \texttt{i\_n} is the last instruction of the program, since no variables are live after the program ends, we start from this assumption at the beginning of the procedure.
Then for jump instructions we can simplify the first dataflow equation by removeing \texttt{def[i]} as jump instructions never define variables.

Now, Because of the different semantics of $\phi$ instructions we must define their dataflow equations separately. In particular we define the liveness information of the whole $\phi$ section instead of for single instructions, this is because, as was explained in \Cref{subsec:phi}, $\phi$s are executed parallelly.
We compute:
\begin{align*}
  \texttt{live\_in[ps]} &= \texttt{$\phi$\_defs[ps]} \cup \texttt{live\_out[ps]} \\
  \texttt{live\_out[ps]} &= \bigcup \limits_{\texttt j \in \texttt{succ[ps]}} \texttt{live\_in[j]}
\end{align*}
where \texttt{$\phi$\_defs[ps]} contains the variables defined in the $\phi$ section.

Starting again with \texttt{live\_out[ps]}, we define it as the the union of the variables that are live before the first ALU instruction of the block. \texttt{live\_in[ps]} is instead the set of variables that are defined in the $\phi$ section together with the variables that are required after the $\phi$ section, intuitively the variables in \texttt{phi\_defs[ps]} are already defined before reaching the start of the block since their execution happens during the jump.

% \subsection{Liveness Analysis Function}

% We take into consideration the previously defined dataflow equations to create a function that performs liveness analysis over the whole control flow graph.

% \begin{alltt}
% Fixpoint analyze_program (p : program) (fuel : nat) : ProgramInfo.dict * set reg :=
%   match fuel with
%   | O =>
%     let (iis, live_in) := analyze_block p nil in
%     (programinfo_insert ProgramInfo.empty (get_lbl p) (BlockInfo iis), live_in)

%   | S fuel' =>
%     let bs := successors p in
%     let results := map (fun p => analyze_program p fuel') bs in
%     let (pi, live_out) :=
%       fold_left
%         (fun '(pi_acc, live_out) '(pi_succ, live_in) =>
%           (programinfo_merge pi_acc pi_succ, regs_union live_out live_in))
%         results
%         (ProgramInfo.empty, nil)
%     in
%     let live_out := regs_union live_out (phi_uses p) in
%     let (iis, live_in) := analyze_block p live_out in
%     let pi := programinfo_insert pi (get_lbl p) (BlockInfo iis) in
%     (pi, regs_diff live_in (phi_defs (get_phis p)))
%   end.
% \end{alltt}

\section{Coloring}
\label{sec:coloring}

Now that we extracted the liveness information from our CFG we use it to build the interference graph.

\subsection{Interference Graph Construction}

The reasoning behind the creation of the interference graph is straightforward, we go through every live set computed in the previous step and we create a clique containing its elements. This follows intuitively by the fact that if two variables are live in the same instruction then they interfere.

The function that does so is defined as follows:

\begin{alltt}
Definition get_ig (pi : ProgramInfo.dict) : InterfGraph.dict :=
  fold_left
    (fun g l =>
      match ProgramInfo.get pi l with
      | Some (BlockInfo iis) => ig_insert_instinfos g iis
      | None => g
      end)
    (ProgramInfo.keys pi)
    InterfGraph.empty.
\end{alltt}

Where \texttt{ig\_insert\_instinfos} is a function that given an interference graph and a list of live sets returns a graph where a clique containing the elements of the set is added for each element of the list.

\subsection{Coloring}

As explained in \Cref{subsec:ssara} register allocation is considered equivalent to the task of register assignment.
To perform the coloring we proceed this way:
By \Cref{def:ig} a chordal graph is a graph for which there exists a perfect elimination ordering, that is, there exists a simplicial node such that, if we remove that node the graph is still chordal and, the perfect elimination ordering is then the ordering in which the nodes are removed.

\section{SSA Destruction}
\label{sec:destruct}

The final phase rewrites the program to remove SSA-specific constructs such as $\phi$ nodes. This involves inserting move instructions and reordering instructions where necessary to preserve correctness while transitioning to a non-SSA representation.